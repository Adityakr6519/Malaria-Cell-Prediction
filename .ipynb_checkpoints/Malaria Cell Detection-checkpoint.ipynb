{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64126098",
   "metadata": {},
   "source": [
    "#                                             <center>Malaria Cell Detection</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776dad1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://media.giphy.com/media/132Afq7xvIjJy8/giphy.gif\" width=350></ceenter>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303145eb",
   "metadata": {},
   "source": [
    "# Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f09123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as k\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils  import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a5f36",
   "metadata": {},
   "source": [
    "# Converting images to same pixels size and array conversion for input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fd8b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAATBElEQVR4nLV6W49u2XXVmJe19v6q6lzsdFoxDiRCQQo8cTEoLbAleMgDEhcFJbbIMz8LIdnpWA4SCFlcAiEoliMkMG9IBIiQkzQYaLfdl7p8e6154WHub59q0+326bS3jkpVdb7ae17HGHOuDfz4r/O3/tn9f/inP6ab04/pvgDe+/e/ERHMGhFEYmOykqoSUUQ48vlrv1yfvPuPX7/+y3/r4z1FPzmDf/B6eNhaa2OMDBA5MWz4nJ7py7I8jhz9McL4x83Au9/8SmQSyRgjkwgyhoE0MzO9Yj/nZGYgmFmUmZkoRQTCzBCRpV+bOTPf/JW//bIGfJwMvPfN3wAQjvQ5NjMLj1m2utvYjDUAZBCzbNuWmUQhSkRBM4mMmVtDcrSmNn2OW1VVbR/DmI/jwLQwc3efm4nItJhumRRuEZEJzCGic06AzYwomWkMEBERiXCm9d4hfHd7d319zRKAz2kfw5iXK6G3/s2Xh8UMnB/MhmUSmDwzItJSRGakgNxGW9RmJGdEZEoXdXcRmXMCaG1x92QnIhFpnXoXbdxaE5Grq6tnr/2dT9KB73/j9TncZ8xpmfSw+bYNn8HSkikzI4KTRSSZzAwOiEWgLxyOmLAxzaFNmCFtMfMMSYqM2VpjiXXtLFgWFZHe+9q59379Cx/txkc78N7v/uM55/k8t/O04dPjfrOYQUQRIJXMtBmqSpxmpqqiOu43Ve0qrcvd7QZEhiYFM48xmLtwizQIMr33RkTTtqurtTVprZ26rKsua7t+7e/+cPM+ugfGsG3Y/cO04TbdgyPYk5SQnAhyD9W2zW1ZmqpGRGyW7yrxsk2jJ+3ZzfO78zv3230SVFmoIzl8MqXNSKYx3N2ZeY4E0mxKMiEC4yPN+wgH3vy3r48xb2/P4TRm2IhIskBGzCRQIMEp7g6AiBhC4XTb8junK3nSpL/1nbfw6eZ0zafkxm1p53nLmpkWyZkewUwqzBFxPm/urbX2AEsA8tEF8qGf+N5vfzUzt+HbNu/ut3Ce090zImYmETEAijmisUhvE76osPN4x+gP+ve+Nf/zf/r9ZzfPBm8/82d/7jN/5jPtT1K7zqG3s92mjiCbIz1m7736+/J1Xl1dLdqI4/Skrevy2V/84sdx4K1//fo283yeHvjuW+8QyS4B3IMJAIMCjiAB88KWIcEt+v/+vTf5vzz99u+8NZ3Z4DQim5z4lZ955cmfuF5+UtbPQn/Crl7VO7uljGkbM4sIM5sZM6uquy9Lu3rSm/Dpallbe+Vv/NIH2vmhJXR39zC2eNgMLADPYQBEOTPdA0AkWIUI4UEBZWYRZb159vyN997mp/ypmyedFseY9/Tuu+/+39974/7NZ+urV/f/7Z2f+kvPfvrmuTTzpCzSdo+I+n6M4e6stJ1pSrHHh2bggx34o6//w+2cMwnU7h+2sc0gEBESJEo2MzMBgESEFAAYTES0kDyj00/303Nu3Lc5FELn+ent+vw/5e03vpvjJ986v/3sTz9597236SoK+yvwzDznzExmNvc5nJlb0/OYrPLtf/HrP/s3//6P5MCb/+or796ex/QxYhvmnsxMTCIyxhARIsrMotXMFJEKXtXYs1durl5bcUeZPMYmvX3njf8Fl/78+vvbm2+8+e3nz5/+0R/84Wc/9/ODHtL9al2LSdy9vgFAQGVjzkmkm0xV/lEzcD4Ps3CnBLe2zHlPDHMHULkGshiUEolIkkAiE6AI166nV3nB2kXPU4Ztf+Hnf+7+dvs/v3++zdP2X89PX1nlT62BqcLMfN42VZ1mmVnZGHMyEQGlApnZLeVDEOl9v/3ub73uI95+92EaHs4jnNydiMbcPFlEtu2htcZMzBwRzAygLZ2ICkPCvB6poHVdtzl00cwUEHzcvTPee2vGxM1PPdXF7H48zBHIdV0jom5YedgNEibmvui6rqqqffy5v/cPflgGfNj9/XAjm44UZphZRIRnUtZ0kpkizd0AqOq2bezeWqvsiwiASKNlebBzZCg0gbPNteXTV69PzxNGwXl/9vuxufu6rpSgBIPSIz2YOQkRgUxE+IyBSQtrk//xz//RzZPTq1/40gc48OZvftlmZtDYPIBtnJnE3SkZ4Cr31hozxhiqMuckoqurKwsvZ1S1Hh+GmMHMTOzDASyqD9u9NKhIRiAoM6eb8qV/OCMDgDaOiP2JQCXZ3c/nc5K0tpwf5uOgv+iMC5xF3VFVI/e6V251lzln1WW1bO99TsvEeUywuAezRMRyugKzpVkaBNx4+FjbFbNaJCuZj3TPmB4z4KwEIhYh5sgE0YGq5/N5/97cLLfN58wPduA8fGxpE5FGCQZTUjrMDIgMIkhERFIEmBsRB1KaEKGJYG+JbK15jISrakFWTQHnOSiZQW6J5K7i7mAQw91neBB2ooxgBlGWuh5jAHDkHO5G24xv/8vX31dCb//26264P9uc2xgjHAGfbjZ3cGRmjplClFI9mpmZVBKo6sfMmIlFRWQbo7V2CARmPjDXzOBBIufzg7YurL0t7k6ZymKcdf/z+ayqY4z6cYxxOp20LXNaEJh/MAM8hpmFG7W2EPG2bRlUfwzsrZzmnJWQ3WhKIiL3MDMiaq15RinqiGitqeq6rofU27YHeAC4v78nkmVZTqeTmVWiDh6ICBYSkdIXVb1mdn9/Gw4Ksfl+B4o7IrJszcxlOVVLWM2O7mEOoGJ/Pp8BVH4RKGB1t2rrinQ5X9aUHTW/A4hAPXRZlrpPfT4RLFRU4+6JqLVAcWWRtLvPecTw4kB1Z8WpgL9cqt9UOJkZkRUkItq2rYZDIgA554SwiNTap7X2AyRddUyxk2sFQkSWZalPYtdEefhf8SpL9t9kmln4Dk3va+L9MW5FIjufE5UF7u4Z2lu5V+JRVZV3nZVMrUmEAUGcRKSqZXclgYgoSrHBzNxTRMxsjEEMYhxipAzIzAyYxZ7/iJr7Dn3x37/+1T/8za/i4IGL9wkAHkQlDVBxYmYwRQSpCLOqMgMIgEs2tiZElBc5CWDbttZafVNdqFTtNImIQQksa3f3TGcGJSIjszQElNsht44Qq7ZMqohM23rruwNHmiLCzIA9ccc15wQTqQAYYzBDtdeGhKq6mDNdmkRaOiqQ5/O5aq++ZuxS+fp0M+dclqXg0n0PX4lQJB2yNHkfQnbpBeJLqblleALg7/3WV9KDiGJaup+WtYoEgPtel9KUd4JE751ZLZyEhs1AZpKPGQHVjjxA9kUhVTVWJazrmhRt0QhLziDM8G3bSBiAspjPMQYhI8JmZBAnEyQc1ah7QV4a9QKUY2amsvjFagCn07IjNwBw773EVoRFxLZt9UgVUtUSkkdBttZ2qddaIVJbl3Vdl2U5GrTCLCLL1cnMWGXYvMh1qHaAI5BBmUQkZW2xyiH4lEEV8qa0ne0FNxMV/IsIMSe/cJqIIrP3npmJ3LYtAUH23t0sM9dlOTC0+u9yS9olJxJE5DtLm5kufZ6niGSmCI9h6a66cCKR6Qmtmm2q9D4HjgfsVTj3vHhE1cDRQ+V9zd3atVoTlJlIwtqamSlzwcvRfEcJHW1WP2Ymi1SliUg4AmCRGAZk5o51aRnhJbEuo3MlYr8/e0Ylmi4zNZJwYd96ahlkZmY2xrn3XgZV6spPCrrA384hZdxhfXHiEfKD6QAQRFV77+6xo5AymGPatj2kG1Buv0CXWnTvGTAzsGQmmHx4TTmqOt0oQUSnvjqjugcIIsQuXV1ZRBS5U7hTEFAOl+eV2FJE+3jlXtmrVtm2TaVv20bEAvKs2ZKkC4yEdj8FUgjqnuRIIIIAsIj0ddm2rbpnT9xFw6lqbTuO3m+tVRhKaZWwmnOWEgnLQ1Acsa/AVxLGGJwouc7MaV49vSzLhdqpt9a7RkTCRRmUzJQZIiJCxFm0U6zFEAaiNyGEMrGSY7dViKtqWXd6L9VZfyvEDEr3CFcVRKQHKIq835drESLCpfOGW3XzrpRAjPA5i9cr3pkJN0ZmOiuRCglbWqQV1SoBZAC4JiliBhOYWmsFQ3KRKyJSi4lq5spAybIfaMrSTmOMsqPa4OiluOjqAtwDrOsmRNl7ByUxiPkA4qS9boFoXVRZldYTa8smAoCffv6LycTMrbUS8Qd0lJVlTbXd8dT6zGVY2ZuydGWRV8npStoBQeWVj8mJcqZrC9ulrgjVbh1C3ISUSXB9fUpOUCxdiVJVWqfIKYq+8C4lRKSty8P3b5mFW9IIVc2kabZTHZEQVLkGmIvSVPfdq3LJzLS9mGAKfI8tQ1mvdGEij4rLQatExIygIE6WRkSkcI9laeUeCbMSUYiCyUUaHs0D2bu6mxAdka4nXYpkp+SIizY0O2rgaNnYgcKLqrdt44TS3qy7KKoTnUx4HDPdgUvFNXwZu4kgwqrSe6t6riIvxb47AE5VPZ2W3oSRybmuy/SxnLpngKlsjVqEV8/QToeH7Jlz1thxSClmLsCpJh4PZyU2s/SgvBCccJVclVOpvYxITxt2hGNHUmHR7Iv03ltr67ruDqhqV0bmunYWYsY2z6fTSkQQQED6gkcvg1/WH1bMjpwUBB8OF5HXcFz/dZBX6UoASbvUO9BWpR9DYjVS+aDKEZbpJdT3ygTw9K9+6eYLX9SuoGCOTF963/+GWEDMFAjPY6rcAX661eOPtNS4dATVMhxZ/5LJkUEIoSQEEgAlfNox/hMJoVgIIkxCAfTel7UlHOlNSQUsoaruFwfqak1EeF3Xq+uVGa3JtFG+FsIcO5IX3jNXvMcYc86IqKmxKOnxZ+gyKBZeBSGZImK6HW3weKatLhLiJmpWqiSXpa2nLkqXIZvvvvVPHq98Qxr3RSOcKCONiKYN6Y2I6aIfiAjIKqhDFVZvFXQebF0Y8AKFEo+FIwBHigh4J2kwHeBRVV4Oi3BEnE6nhEVYqfp69PXnfumRA1JQRcsqoiDKiKrpMJs19DxW1DsIXLip2K0G9mMQq5khL+cXFHu74zKs7u4xBfborOtqZlWlzHw6nSr/XbR3XddFhFQZiEcoBACoaaM1aY21xfVNP63cGmF3Iw94OVa5F2CNUpoF6keYC5ceq87MpNj7eC8SkcMAZs4Lo5fRqirCLFg7a0tt6AtXIRczvM8Bi9JVcVqkLyIcSxfhWJbWlRHRRCrFRxIAEtFDvRJnRIwxqitKru29cZHTllEm7vcR5qY1WNYhUAWlhoSER9ppkXVtonm1NqEkon0/U0D8qAdw/82vRZqZjc22zS3o4Wx3t2fz7H0dw0ik8G6PYhW0h6q01h7Od7W+JhJchsb6sIjM80ZE0ncxe5wsHUNCAehFlXQilPgR8vUk60lE6ObJVXJe/cVffpG3xw5c/bUv3nz+V9d1vb459a7MYOTVqT+5uXp4uOudbZxrnebuFeBDZh8bsUN7l97Oy9HTIdQLbaq0qmd670fbVOzLQyBYYln6uvamLFxHux+ynX7RzEKqvJ60a/bmXRE+nj2/HvNeNM0HC1oXj4kIRDB8nO8RF5F8GeiqYY4zNW5aL1aUV/UaDpIjoqb7qo3CaxEGxdppVfQeKlDVvrYazW6/9bXD2g84I4sAs64rVy3e3t6frnRaPrm5Pj9snpPomOsXVY20demZKZet02OJdvBoCdXz+VzAtU/9aYgXiktEtJYYsKW3ZW1Lp+XUtUGVSxxl5s3nXhx9f0AGll/4lXpk7/365vT8Uzdrp6XzadWr62Vpuq4diGVtxEm8LwkvAwMOsLo0OnBB2zFG7/1Q6Rm0rmvVz9Mnz4Vb0bkq967L0pWpLV2VVZkIIi+WEcf1ES8jvPeNL0fEts3t7MPCPcbMaQnW8/ms2kv/zFmCfl/lMvOxWizAqQwceIpHZ0frcmVmrbUmwgxVbZ2WLsy4ebJKI2Jf197+/Eue1Ncl0jKHKtOJ8DAmiXa+vds8XZREE2AgRah8iGnurkvny1R13OqAo/eN+QllSBMRWtdeI68ISePr08qcvUk+Sun/f/0I7wt949cyfU4Xbnd3d0nt/mFs08yMpI0xichmZBLnLkvbuhRKHqB+zC5lfWs7pQheHGQQsJ6kd21N2qLa5MlrHxz1l3MAwP3vfrWwLxwPY07L8zbNjEgyaEa4pQ+PACItXJdegHhwLTMjOXI/zY4wAK2JMjNqQ6HL0kSjL/oTf/1LH2HQyzpwXO/8u1+Tvowxxqy1fY79zb6wGWPU65U7euZlI1ZHJIWnF6SnOu5f+uVARPCZX/zVlzKmrpd7a7G1hoz9zIaqyk8WrhbRoZK1aGKV2hT1pbk7c0akCkdEaxoR2hiIZVncfVl6730/mnj562O++Pre7/z6nLNemIuk8/nc+7pt29yGiGhvx5IQj4CILgv3va6UazXGwKe/8MPeavrkHXh8ff8br7fW5pyU7O6csKyBMI7RGQBBcCHmT71Mlf/w6xN4d7prW9Y1MymxqERE3w9Ga26WMUZrjUhqsZcfCokf5/qxvL1+/82vASjdWsMDEQF8/flf+cSf9f8A5ujQ/EPBt+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img(\"Malarial Cell Image Data\\cell_images\\Parasitized\\C33P1thinF_IMG_20150619_114756a_cell_181.png\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4188781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting tensorflow as backend\n",
    "os.environ[\"KERAS_BACKEND\"]=\"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d13a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get same output when using rand\n",
    "np.random.seed(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a15697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store initial path and other two to store all data and their labels\n",
    "image_dir=\"Malarial Cell Image Data/cell_images\"\n",
    "data_x=[]\n",
    "data_y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef47f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path for parasited cells\n",
    "para_img=os.listdir(image_dir+\"/Parasitized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e37e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379d67be59484e6284ad2a9a32e976a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fetching parasited images and conerting same pixels size and array format and storing in data along with labels\n",
    "for i in tqdm(para_img[:4100]):\n",
    "    path=image_dir+\"\\Parasitized\"+\"\\\\\"+i\n",
    "    img_array=cv2.imread(path)\n",
    "    img_resized=Image.fromarray(img_array,\"RGB\")\n",
    "    img_resized=img_resized.resize((64,64))\n",
    "    img=np.array(img_resized)\n",
    "    data_x.append(img)\n",
    "    data_y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1a84ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full paths of uninfected cells\n",
    "un_img=os.listdir(image_dir+\"/Uninfected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ed2431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1ab6c332a146a0a96b7fb21b2b1881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fetching uninfected images and conerting same pixels size and array format and storing in data along with labels\n",
    "for i in tqdm(un_img[:4100]):\n",
    "    path=image_dir+\"/Uninfected\"+\"/\"+i\n",
    "    img_array=cv2.imread(path)\n",
    "    img_resized=Image.fromarray(img_array,\"RGB\")\n",
    "    img_resized=img_resized.resize((64,64))\n",
    "    img=np.array(img_resized)\n",
    "    data_x.append(img)\n",
    "    data_y.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98275a3",
   "metadata": {},
   "source": [
    "# Splitting data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a323d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to 2 parts for testing and training \n",
    "x_train,x_test,y_train,y_test=train_test_split(data_x,to_categorical(data_y),test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5659fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,0) means uninfected while (0,1) means infected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c630d2",
   "metadata": {},
   "source": [
    "# Preaparing Model CNN + Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d22042",
   "metadata": {},
   "source": [
    "<center><img src=\"https://media.giphy.com/media/5k5vZwRFZR5aZeniqb/giphy.gif\" width=300></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6629b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining Architecture of model\n",
    "inp=k.Input(shape=(64,64,3))\n",
    "conv1=k.Conv2D(32,kernel_size=(3,3),activation=\"relu\",padding=\"same\")(inp)\n",
    "pool1=k.MaxPool2D(pool_size=(2,2))(conv1)\n",
    "norm1=k.BatchNormalization(axis=-1)(pool1)\n",
    "drop1=k.Dropout(rate=0.2)(norm1)\n",
    "conv2=k.Conv2D(32,kernel_size=(3,3),activation=\"relu\",padding=\"same\")(drop1)\n",
    "pool2=k.MaxPool2D(pool_size=(2,2))(conv2)\n",
    "norm2=k.BatchNormalization(axis=-1)(pool2)\n",
    "drop2=k.Dropout(rate=0.2)(norm2)\n",
    "flat=k.Flatten()(drop2)\n",
    "hidden1=k.Dense(512,activation=\"relu\")(flat)\n",
    "norm3=k.BatchNormalization(axis=-1)(hidden1)\n",
    "drop3=k.Dropout(rate=0.2)(norm3)\n",
    "hidden2=k.Dense(216,activation=\"relu\")(drop3)\n",
    "norm4=k.BatchNormalization(axis=-1)(hidden2)\n",
    "drop4=k.Dropout(rate=0.2)(norm4)\n",
    "out=k.Dense(2,activation=\"sigmoid\")(drop4)\n",
    "model=keras.Model(inputs=inp,outputs=out)\n",
    "model.compile(optimizer=\"Adam\",metrics=[\"accuracy\"],loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acdca2e",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b150d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "45/45 [==============================] - 17s 301ms/step - loss: 0.5014 - accuracy: 0.7955\n",
      "Epoch 2/15\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.3224 - accuracy: 0.8552\n",
      "Epoch 3/15\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.2672 - accuracy: 0.8793\n",
      "Epoch 4/15\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.2189 - accuracy: 0.9056\n",
      "Epoch 5/15\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.1799 - accuracy: 0.9287\n",
      "Epoch 6/15\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.1316 - accuracy: 0.9479\n",
      "Epoch 7/15\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.1091 - accuracy: 0.9577\n",
      "Epoch 8/15\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0912 - accuracy: 0.9639\n",
      "Epoch 9/15\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0748 - accuracy: 0.9713\n",
      "Epoch 10/15\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0652 - accuracy: 0.9732\n",
      "Epoch 11/15\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0502 - accuracy: 0.9828\n",
      "Epoch 12/15\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0495 - accuracy: 0.9834\n",
      "Epoch 13/15\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0439 - accuracy: 0.9829\n",
      "Epoch 14/15\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0400 - accuracy: 0.9843\n",
      "Epoch 15/15\n",
      "45/45 [==============================] - 15s 322ms/step - loss: 0.0351 - accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20711208d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting aka training the model\n",
    "model.fit(np.array(x_train),y_train,batch_size=128,verbose=1,epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5120fff",
   "metadata": {},
   "source": [
    "# Predicting a.k.a Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4150390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# getting model predictions\n",
    "y_predict=model.predict(np.array(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ba97d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02915121, 0.9799233 ],\n",
       "       [0.9994389 , 0.00133332],\n",
       "       [0.1114294 , 0.80060905],\n",
       "       ...,\n",
       "       [0.8263661 , 0.5770953 ],\n",
       "       [0.26437783, 0.9227317 ],\n",
       "       [0.9957358 , 0.01202773]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a748a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coversion of prediction to result format\n",
    "for i in range(len(y_predict)):\n",
    "    idx1=y_predict[i][0]\n",
    "    idx2=y_predict[i][1]\n",
    "    if idx1>0.5:\n",
    "        y_predict[i][0]=1\n",
    "    else:\n",
    "        y_predict[i][0]=0\n",
    "    if idx2>0.5:\n",
    "        y_predict[i][1]=1\n",
    "    else:\n",
    "        y_predict[i][1]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49333b10",
   "metadata": {},
   "source": [
    "#  Check for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9cbd10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction count :  2038\n",
      "Incorrect prediction count :  422\n"
     ]
    }
   ],
   "source": [
    "# Counting correct and wrong predictions\n",
    "correct=0\n",
    "wrong=0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i][0]==y_predict[i][0] and y_test[i][1]==y_predict[i][1]:\n",
    "        correct+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "print(\"Correct prediction count : \",correct)\n",
    "print(\"Incorrect prediction count : \",wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f347149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score :  82.84552845528455\n"
     ]
    }
   ],
   "source": [
    "# Accuracy using r2_score method\n",
    "R2_score=correct*100/(correct+wrong)\n",
    "print(\"R2_score : \",R2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c7328",
   "metadata": {},
   "source": [
    "<center><img src=\"https://media.giphy.com/media/3mgqx7KV95ESazDCCn/giphy.gif\" width=500></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
